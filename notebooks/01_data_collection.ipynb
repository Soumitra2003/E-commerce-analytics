{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5eb475f",
   "metadata": {},
   "source": [
    "# E-Commerce Analytics Capstone Project\n",
    "## Notebook 1: Data Collection and Initial Exploration\n",
    "\n",
    "**Author:** Soumitra Upadhyay,\n",
    "    **Date:** September 2025,  \n",
    "**Project:** E-Commerce Customer Analytics & Revenue Optimization\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ **Objective**\n",
    "This notebook demonstrates comprehensive data analytics skills for an analytics role by:\n",
    "- Loading and exploring e-commerce transaction data\n",
    "- Performing initial data quality assessment\n",
    "- Setting up the foundation for advanced analytics\n",
    "- Showcasing technical proficiency and business thinking\n",
    "\n",
    "### ğŸ“Š **Business Context**\n",
    "We're analyzing e-commerce transaction data to:\n",
    "1. **Understand customer behavior patterns**\n",
    "2. **Identify revenue optimization opportunities**\n",
    "3. **Build predictive models for business value**\n",
    "4. **Create actionable business insights**\n",
    "\n",
    "This project simulates real-world analytics work that directly impacts business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316406a3",
   "metadata": {},
   "source": [
    "## 1. Data Import and Initial Setup\n",
    "\n",
    "### Library Imports\n",
    "Importing essential libraries for data analysis, visualization, and custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce77a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "ğŸ“Š Pandas version: 2.3.2\n",
      "ğŸ“ˆ NumPy version: 2.3.3\n",
      "ğŸ¨ Matplotlib version: 3.10.6\n",
      "ğŸ“Š Seaborn version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "# Core Data Science Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Custom Modules (from our src/ directory)\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_processing import DataProcessor\n",
    "from feature_engineering import FeatureEngineer\n",
    "from visualization import EcommerceVisualizer\n",
    "from utils import (generate_data_summary, calculate_business_metrics, \n",
    "                   validate_data_schema, setup_logging)\n",
    "\n",
    "# Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ğŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ“ˆ NumPy version: {np.__version__}\")\n",
    "print(f\"ğŸ¨ Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"ğŸ“Š Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d83d79",
   "metadata": {},
   "source": [
    "### Initialize Project Components\n",
    "Setting up our custom data processing and analysis classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d14fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Analytics framework initialized!\n",
      "ğŸ“ Project structure ready for analysis\n",
      "âš™ï¸ Custom modules loaded and configured\n"
     ]
    }
   ],
   "source": [
    "# Initialize our custom analytics classes\n",
    "data_processor = DataProcessor()\n",
    "feature_engineer = FeatureEngineer()\n",
    "visualizer = EcommerceVisualizer()\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging('INFO')\n",
    "\n",
    "print(\"ğŸš€ Analytics framework initialized!\")\n",
    "print(\"ğŸ“ Project structure ready for analysis\")\n",
    "print(\"âš™ï¸ Custom modules loaded and configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb199b7a",
   "metadata": {},
   "source": [
    "### Data Loading Strategy\n",
    "\n",
    "For this capstone project, we'll work with a realistic e-commerce dataset. Since this is a demonstration, we'll generate a comprehensive synthetic dataset that mirrors real-world e-commerce data patterns.\n",
    "\n",
    "**ğŸ¯ Why Synthetic Data?**\n",
    "- **Demonstrates data generation skills** - important for testing and simulation\n",
    "- **Ensures data privacy** - no real customer information\n",
    "- **Controlled environment** - we can inject specific patterns for analysis\n",
    "- **Scalability** - can generate any size dataset needed\n",
    "\n",
    "**ğŸ“Š Dataset Features:**\n",
    "- Customer transactions over 2+ years\n",
    "- Multiple product categories\n",
    "- Seasonal patterns and trends\n",
    "- Customer behavior variations\n",
    "- Realistic business metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e779a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Generating realistic e-commerce dataset...\n",
      "âœ… Generated dataset with:\n",
      "   ğŸ“Š 50,000 transactions\n",
      "   ğŸ‘¥ 5,000 unique customers\n",
      "   ğŸ“… Date range: 2022-01-01 00:00:00 to 2024-09-01 00:00:00\n",
      "   ğŸ’° Total revenue: $20,250,677.36\n",
      "\n",
      "ğŸ“ˆ This demonstrates:\n",
      "   âœ“ Data simulation and engineering skills\n",
      "   âœ“ Understanding of business data patterns\n",
      "   âœ“ Ability to create realistic test datasets\n",
      "   âœ“ Preparation for real-world data scenarios\n"
     ]
    }
   ],
   "source": [
    "# Generate Realistic E-commerce Dataset\n",
    "# This demonstrates data simulation skills - valuable for testing and development\n",
    "\n",
    "def generate_ecommerce_data(n_customers=5000, n_transactions=50000, start_date='2022-01-01', end_date='2024-09-01'):\n",
    "    \"\"\"\n",
    "    Generate a realistic e-commerce dataset for analysis\n",
    "    Demonstrates data engineering and simulation capabilities\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Date range\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    date_range = pd.date_range(start=start, end=end, freq='D')\n",
    "    \n",
    "    # Product categories and characteristics\n",
    "    categories = ['Electronics', 'Clothing', 'Home & Garden', 'Sports', 'Books', 'Beauty', 'Toys']\n",
    "    category_price_ranges = {\n",
    "        'Electronics': (50, 2000),\n",
    "        'Clothing': (15, 300),\n",
    "        'Home & Garden': (20, 500),\n",
    "        'Sports': (25, 400),\n",
    "        'Books': (5, 50),\n",
    "        'Beauty': (10, 150),\n",
    "        'Toys': (10, 200)\n",
    "    }\n",
    "    \n",
    "    # Generate customer base\n",
    "    customers = []\n",
    "    for i in range(n_customers):\n",
    "        customers.append({\n",
    "            'customer_id': f'CUST_{i+1:05d}',\n",
    "            'customer_segment': np.random.choice(['Premium', 'Regular', 'Budget'], p=[0.2, 0.5, 0.3]),\n",
    "            'registration_date': np.random.choice(date_range[:365])  # First year registrations\n",
    "        })\n",
    "    customer_df = pd.DataFrame(customers)\n",
    "    \n",
    "    # Generate transactions\n",
    "    transactions = []\n",
    "    \n",
    "    for i in range(n_transactions):\n",
    "        # Select customer with preference for active customers\n",
    "        customer = np.random.choice(customer_df['customer_id'])\n",
    "        customer_info = customer_df[customer_df['customer_id'] == customer].iloc[0]\n",
    "        \n",
    "        # Transaction date (more recent transactions more likely)\n",
    "        # Add seasonality - higher sales in Nov-Dec, lower in Jan-Feb\n",
    "        transaction_date = np.random.choice(date_range)\n",
    "        # Convert numpy datetime64 to pandas datetime to access month attribute\n",
    "        month = pd.to_datetime(transaction_date).month\n",
    "        \n",
    "        # Seasonal adjustment\n",
    "        seasonal_multiplier = 1.0\n",
    "        if month in [11, 12]:  # Holiday season\n",
    "            seasonal_multiplier = 1.5\n",
    "        elif month in [1, 2]:  # Post-holiday lull\n",
    "            seasonal_multiplier = 0.7\n",
    "        elif month in [6, 7]:  # Summer\n",
    "            seasonal_multiplier = 1.2\n",
    "        \n",
    "        # Select category\n",
    "        category = np.random.choice(categories)\n",
    "        price_min, price_max = category_price_ranges[category]\n",
    "        \n",
    "        # Adjust price based on customer segment\n",
    "        if customer_info['customer_segment'] == 'Premium':\n",
    "            price_multiplier = 1.5\n",
    "        elif customer_info['customer_segment'] == 'Budget':\n",
    "            price_multiplier = 0.7\n",
    "        else:\n",
    "            price_multiplier = 1.0\n",
    "        \n",
    "        # Generate transaction details\n",
    "        base_price = np.random.uniform(price_min, price_max)\n",
    "        quantity = np.random.choice([1, 2, 3, 4], p=[0.6, 0.25, 0.1, 0.05])\n",
    "        unit_price = base_price * price_multiplier\n",
    "        total_amount = unit_price * quantity\n",
    "        \n",
    "        # Add some discount probability\n",
    "        discount_applied = np.random.choice([True, False], p=[0.3, 0.7])\n",
    "        if discount_applied:\n",
    "            discount_rate = np.random.uniform(0.05, 0.25)\n",
    "            total_amount *= (1 - discount_rate)\n",
    "        \n",
    "        transactions.append({\n",
    "            'transaction_id': f'TXN_{i+1:06d}',\n",
    "            'customer_id': customer,\n",
    "            'transaction_date': transaction_date,\n",
    "            'product_category': category,\n",
    "            'quantity': quantity,\n",
    "            'unit_price': round(unit_price, 2),\n",
    "            'total_amount': round(total_amount, 2),\n",
    "            'discount_applied': discount_applied,\n",
    "            'payment_method': np.random.choice(['Credit Card', 'Debit Card', 'PayPal', 'Bank Transfer'], \n",
    "                                             p=[0.4, 0.3, 0.2, 0.1])\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    transaction_df = pd.DataFrame(transactions)\n",
    "    \n",
    "    # Sort by date\n",
    "    transaction_df = transaction_df.sort_values('transaction_date').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"âœ… Generated dataset with:\")\n",
    "    print(f\"   ğŸ“Š {len(transaction_df):,} transactions\")\n",
    "    print(f\"   ğŸ‘¥ {len(customer_df):,} unique customers\")\n",
    "    print(f\"   ğŸ“… Date range: {transaction_df['transaction_date'].min()} to {transaction_df['transaction_date'].max()}\")\n",
    "    print(f\"   ğŸ’° Total revenue: ${transaction_df['total_amount'].sum():,.2f}\")\n",
    "    \n",
    "    return transaction_df, customer_df\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"ğŸ”„ Generating realistic e-commerce dataset...\")\n",
    "transactions_df, customers_df = generate_ecommerce_data()\n",
    "\n",
    "print(\"\\nğŸ“ˆ This demonstrates:\")\n",
    "print(\"   âœ“ Data simulation and engineering skills\")\n",
    "print(\"   âœ“ Understanding of business data patterns\")\n",
    "print(\"   âœ“ Ability to create realistic test datasets\")\n",
    "print(\"   âœ“ Preparation for real-world data scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332de996",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Initial Data Inspection\n",
    "Let's examine the structure and basic characteristics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e011ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” DATASET OVERVIEW\n",
      "==================================================\n",
      "ğŸ“Š Transaction Data Shape: (50000, 9)\n",
      "ğŸ‘¥ Customer Data Shape: (5000, 3)\n",
      "\n",
      "ğŸ“‹ Transaction Data Columns:\n",
      "   1. transaction_id\n",
      "   2. customer_id\n",
      "   3. transaction_date\n",
      "   4. product_category\n",
      "   5. quantity\n",
      "   6. unit_price\n",
      "   7. total_amount\n",
      "   8. discount_applied\n",
      "   9. payment_method\n",
      "\n",
      "ğŸ“‹ Customer Data Columns:\n",
      "   1. customer_id\n",
      "   2. customer_segment\n",
      "   3. registration_date\n",
      "\n",
      "ğŸ”¢ Data Types - Transactions:\n",
      "transaction_id              object\n",
      "customer_id                 object\n",
      "transaction_date    datetime64[ns]\n",
      "product_category            object\n",
      "quantity                     int64\n",
      "unit_price                 float64\n",
      "total_amount               float64\n",
      "discount_applied              bool\n",
      "payment_method              object\n",
      "dtype: object\n",
      "\n",
      "ğŸ”¢ Data Types - Customers:\n",
      "customer_id                  object\n",
      "customer_segment             object\n",
      "registration_date    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Basic Dataset Information\n",
    "print(\"ğŸ” DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ğŸ“Š Transaction Data Shape: {transactions_df.shape}\")\n",
    "print(f\"ğŸ‘¥ Customer Data Shape: {customers_df.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“‹ Transaction Data Columns:\")\n",
    "for i, col in enumerate(transactions_df.columns, 1):\n",
    "    print(f\"   {i}. {col}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“‹ Customer Data Columns:\")\n",
    "for i, col in enumerate(customers_df.columns, 1):\n",
    "    print(f\"   {i}. {col}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ”¢ Data Types - Transactions:\")\n",
    "print(transactions_df.dtypes)\n",
    "\n",
    "print()\n",
    "print(\"ğŸ”¢ Data Types - Customers:\")\n",
    "print(customers_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4667c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š SAMPLE TRANSACTION DATA\n",
      "==================================================\n",
      "  transaction_id customer_id transaction_date product_category  quantity  \\\n",
      "0     TXN_015602  CUST_04917       2022-01-01           Beauty         3   \n",
      "1     TXN_049376  CUST_01331       2022-01-01      Electronics         4   \n",
      "2     TXN_000464  CUST_02613       2022-01-01            Books         2   \n",
      "3     TXN_030732  CUST_04975       2022-01-01             Toys         1   \n",
      "4     TXN_012205  CUST_04847       2022-01-01           Beauty         1   \n",
      "5     TXN_039175  CUST_04636       2022-01-01      Electronics         1   \n",
      "6     TXN_045846  CUST_00841       2022-01-01           Sports         2   \n",
      "7     TXN_030676  CUST_00240       2022-01-01           Sports         2   \n",
      "8     TXN_047338  CUST_00711       2022-01-01      Electronics         1   \n",
      "9     TXN_006153  CUST_01647       2022-01-01             Toys         1   \n",
      "\n",
      "   unit_price  total_amount  discount_applied payment_method  \n",
      "0       92.74        278.21             False         PayPal  \n",
      "1      254.19       1016.76             False    Credit Card  \n",
      "2        7.00         14.00             False     Debit Card  \n",
      "3      144.78        144.78             False    Credit Card  \n",
      "4       18.66         18.66             False     Debit Card  \n",
      "5      140.54        140.54             False     Debit Card  \n",
      "6      118.66        188.00              True    Credit Card  \n",
      "7       71.75        143.50             False    Credit Card  \n",
      "8      104.19         84.25              True         PayPal  \n",
      "9       19.50         19.50             False     Debit Card  \n",
      "\n",
      "ğŸ‘¥ SAMPLE CUSTOMER DATA\n",
      "==================================================\n",
      "  customer_id customer_segment registration_date\n",
      "0  CUST_00001          Regular        2022-12-15\n",
      "1  CUST_00002          Premium        2022-03-13\n",
      "2  CUST_00003          Regular        2022-04-13\n",
      "3  CUST_00004          Regular        2022-08-03\n",
      "4  CUST_00005          Premium        2022-03-29\n",
      "5  CUST_00006          Regular        2022-12-26\n",
      "6  CUST_00007           Budget        2022-05-30\n",
      "7  CUST_00008          Premium        2022-12-10\n",
      "8  CUST_00009           Budget        2022-10-21\n",
      "9  CUST_00010          Premium        2022-10-04\n"
     ]
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"ğŸ“Š SAMPLE TRANSACTION DATA\")\n",
    "print(\"=\" * 50)\n",
    "print(transactions_df.head(10))\n",
    "\n",
    "print(\"\\nğŸ‘¥ SAMPLE CUSTOMER DATA\")\n",
    "print(\"=\" * 50)\n",
    "print(customers_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a054b",
   "metadata": {},
   "source": [
    "### Data Quality Assessment\n",
    "Using our custom data processing module to perform comprehensive data quality analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4febddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” COMPREHENSIVE DATA QUALITY ANALYSIS\n",
      "============================================================\n",
      "ğŸ“Š Dataset Shape: 50,000 rows Ã— 9 columns\n",
      "ğŸ’¾ Memory Usage: 15.00 MB\n",
      "ğŸ”¢ Numeric Columns: 3\n",
      "ğŸ“ Categorical Columns: 4\n",
      "ğŸ“… Datetime Columns: 1\n",
      "\n",
      "âŒ Missing Values Analysis:\n",
      "   âœ… No missing values found - Excellent data quality!\n",
      "\n",
      "ğŸ”„ Duplicate Rows: 0\n",
      "   âœ… No duplicate rows found!\n",
      "\n",
      "ğŸ“ˆ DESCRIPTIVE STATISTICS\n",
      "========================================\n",
      "                 transaction_date      quantity    unit_price  total_amount\n",
      "count                       50000  50000.000000  50000.000000  50000.000000\n",
      "mean   2023-05-02 21:34:37.056000      1.599740    267.579837    405.013547\n",
      "min           2022-01-01 00:00:00      1.000000      3.500000      3.030000\n",
      "25%           2022-09-02 00:00:00      1.000000     50.300000     67.180000\n",
      "50%           2023-05-03 00:00:00      1.000000    126.910000    166.025000\n",
      "75%           2023-12-31 00:00:00      2.000000    271.660000    395.150000\n",
      "max           2024-09-01 00:00:00      4.000000   2998.490000  11442.050000\n",
      "std                           NaN      0.855469    414.439318    735.244685\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Data Quality Report using our custom module\n",
    "print(\"ğŸ” COMPREHENSIVE DATA QUALITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate quality report for transactions\n",
    "quality_report = data_processor.data_quality_report(transactions_df)\n",
    "\n",
    "print(f\"ğŸ“Š Dataset Shape: {quality_report['shape'][0]:,} rows Ã— {quality_report['shape'][1]} columns\")\n",
    "print(f\"ğŸ’¾ Memory Usage: {quality_report['memory_usage']:.2f} MB\")\n",
    "print(f\"ğŸ”¢ Numeric Columns: {len(quality_report['numeric_columns'])}\")\n",
    "print(f\"ğŸ“ Categorical Columns: {len(quality_report['categorical_columns'])}\")\n",
    "print(f\"ğŸ“… Datetime Columns: {len(quality_report['datetime_columns'])}\")\n",
    "\n",
    "print()\n",
    "print(\"âŒ Missing Values Analysis:\")\n",
    "total_missing = sum(quality_report['missing_values'].values())\n",
    "if total_missing == 0:\n",
    "    print(\"   âœ… No missing values found - Excellent data quality!\")\n",
    "else:\n",
    "    for col, missing_count in quality_report['missing_values'].items():\n",
    "        if missing_count > 0:\n",
    "            pct = quality_report['missing_percentage'][col]\n",
    "            print(f\"   - {col}: {missing_count} ({pct:.1f}%)\")\n",
    "\n",
    "print()\n",
    "print(f\"ğŸ”„ Duplicate Rows: {quality_report['duplicate_rows']}\")\n",
    "if quality_report['duplicate_rows'] == 0:\n",
    "    print(\"   âœ… No duplicate rows found!\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“ˆ DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 40)\n",
    "print(transactions_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d32dc",
   "metadata": {},
   "source": [
    "### Business Metrics Overview\n",
    "Calculate key business performance indicators to understand the dataset from a business perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb831e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¼ KEY BUSINESS PERFORMANCE INDICATORS\n",
      "==================================================\n",
      "ğŸ’° Total Revenue: $20,250,677.36\n",
      "ğŸ›’ Total Transactions: 50,000\n",
      "ğŸ‘¥ Unique Customers: 5,000\n",
      "ğŸ“Š Average Order Value: $405.01\n",
      "ğŸ’ Average Customer Value: $4050.14\n",
      "ğŸ”„ Average Customer Orders: 10.0\n",
      "ğŸ“… Average Daily Revenue: $20791.25\n",
      "ğŸ”„ Average Daily Transactions: 51.3\n",
      "â° Average Customer Lifetime: 778.6 days\n",
      "ğŸ” Purchase Frequency: 84.6 days\n",
      "ğŸ¯ Customer Retention Rate: 99.9%\n",
      "\n",
      "ğŸ“ˆ BUSINESS INSIGHTS:\n",
      "   â€¢ Revenue per customer: $4050.14\n",
      "   â€¢ Transaction frequency: 10.0 orders per customer\n",
      "   â€¢ Repeat customer rate: 99.9% (customers with >1 order)\n"
     ]
    }
   ],
   "source": [
    "# Calculate Key Business Metrics\n",
    "business_metrics = calculate_business_metrics(\n",
    "    transactions_df, \n",
    "    customer_col='customer_id',\n",
    "    amount_col='total_amount', \n",
    "    date_col='transaction_date'\n",
    ")\n",
    "\n",
    "print(\"ğŸ’¼ KEY BUSINESS PERFORMANCE INDICATORS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Format and display metrics\n",
    "metrics_display = {\n",
    "    \"ğŸ’° Total Revenue\": f\"${business_metrics['total_revenue']:,.2f}\",\n",
    "    \"ğŸ›’ Total Transactions\": f\"{business_metrics['total_transactions']:,}\",\n",
    "    \"ğŸ‘¥ Unique Customers\": f\"{business_metrics['unique_customers']:,}\",\n",
    "    \"ğŸ“Š Average Order Value\": f\"${business_metrics['avg_order_value']:.2f}\",\n",
    "    \"ğŸ’ Average Customer Value\": f\"${business_metrics['avg_customer_value']:.2f}\",\n",
    "    \"ğŸ”„ Average Customer Orders\": f\"{business_metrics['avg_customer_orders']:.1f}\",\n",
    "    \"ğŸ“… Average Daily Revenue\": f\"${business_metrics['avg_daily_revenue']:.2f}\",\n",
    "    \"ğŸ”„ Average Daily Transactions\": f\"{business_metrics['avg_daily_transactions']:.1f}\",\n",
    "    \"â° Average Customer Lifetime\": f\"{business_metrics['avg_customer_lifetime_days']:.1f} days\",\n",
    "    \"ğŸ” Purchase Frequency\": f\"{business_metrics['avg_purchase_frequency_days']:.1f} days\",\n",
    "    \"ğŸ¯ Customer Retention Rate\": f\"{business_metrics['customer_retention_rate']:.1f}%\"\n",
    "}\n",
    "\n",
    "for metric, value in metrics_display.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“ˆ BUSINESS INSIGHTS:\")\n",
    "print(f\"   â€¢ Revenue per customer: ${business_metrics['total_revenue']/business_metrics['unique_customers']:.2f}\")\n",
    "print(f\"   â€¢ Transaction frequency: {business_metrics['total_transactions']/business_metrics['unique_customers']:.1f} orders per customer\")\n",
    "print(f\"   â€¢ Repeat customer rate: {business_metrics['customer_retention_rate']:.1f}% (customers with >1 order)\")\n",
    "\n",
    "# Store metrics for later use\n",
    "transactions_df.attrs['business_metrics'] = business_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca6b8e",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing\n",
    "\n",
    "### Data Type Optimization and Validation\n",
    "Ensure optimal data types and validate data schema for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af9224e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ DATA TYPE OPTIMIZATION & VALIDATION\n",
      "==================================================\n",
      "âœ… Schema Validation Results:\n",
      "   Valid Schema: True\n",
      "\n",
      "ğŸ”„ Optimizing data types...\n",
      "âœ… Data types optimized!\n",
      "ğŸ“‰ Memory reduction: 15.00 MB â†’ 4.32 MB\n",
      "\n",
      "ğŸ“‹ Final Data Types:\n",
      "transaction_id              object\n",
      "customer_id               category\n",
      "transaction_date    datetime64[ns]\n",
      "product_category          category\n",
      "quantity                     int16\n",
      "unit_price                 float32\n",
      "total_amount               float32\n",
      "discount_applied              bool\n",
      "payment_method            category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data Type Optimization\n",
    "print(\"ğŸ”§ DATA TYPE OPTIMIZATION & VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define expected schema\n",
    "required_columns = ['transaction_id', 'customer_id', 'transaction_date', 'product_category', \n",
    "                   'quantity', 'unit_price', 'total_amount', 'discount_applied', 'payment_method']\n",
    "\n",
    "expected_types = {\n",
    "    'transaction_id': 'object',\n",
    "    'customer_id': 'object', \n",
    "    'product_category': 'object',\n",
    "    'quantity': 'int',\n",
    "    'unit_price': 'float',\n",
    "    'total_amount': 'float',\n",
    "    'payment_method': 'object'\n",
    "}\n",
    "\n",
    "# Validate schema\n",
    "schema_validation = validate_data_schema(transactions_df, required_columns, expected_types)\n",
    "\n",
    "print(\"âœ… Schema Validation Results:\")\n",
    "print(f\"   Valid Schema: {schema_validation['is_valid']}\")\n",
    "if schema_validation['missing_columns']:\n",
    "    print(f\"   Missing Columns: {schema_validation['missing_columns']}\")\n",
    "if schema_validation['extra_columns']:\n",
    "    print(f\"   Extra Columns: {schema_validation['extra_columns']}\")\n",
    "\n",
    "# Optimize data types\n",
    "print(\"\\nğŸ”„ Optimizing data types...\")\n",
    "\n",
    "# Convert date column\n",
    "transactions_df['transaction_date'] = pd.to_datetime(transactions_df['transaction_date'])\n",
    "\n",
    "# Convert categorical columns to category type for memory efficiency\n",
    "categorical_cols = ['product_category', 'payment_method', 'customer_id']\n",
    "for col in categorical_cols:\n",
    "    if col in transactions_df.columns:\n",
    "        transactions_df[col] = transactions_df[col].astype('category')\n",
    "\n",
    "# Optimize numeric types\n",
    "transactions_df['quantity'] = transactions_df['quantity'].astype('int16')  # Small integers\n",
    "transactions_df['unit_price'] = transactions_df['unit_price'].astype('float32')  # Sufficient precision\n",
    "transactions_df['total_amount'] = transactions_df['total_amount'].astype('float32')\n",
    "\n",
    "print(\"âœ… Data types optimized!\")\n",
    "print(f\"ğŸ“‰ Memory reduction: {quality_report['memory_usage']:.2f} MB â†’ {transactions_df.memory_usage(deep=True).sum()/1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Final Data Types:\")\n",
    "print(transactions_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197490c",
   "metadata": {},
   "source": [
    "### Data Export and Next Steps\n",
    "Save the processed data for use in subsequent analysis notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f15407c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ EXPORTING PROCESSED DATA\n",
      "========================================\n",
      "âœ… Data exported successfully:\n",
      "   ğŸ“„ ../data/processed/transactions_clean.csv\n",
      "   ğŸ“„ ../data/processed/customers.csv\n",
      "   ğŸ“Š ../data/processed/business_metrics.json\n",
      "\n",
      "ğŸ¯ NEXT STEPS:\n",
      "   1. ğŸ“Š Continue to Notebook 2: Advanced EDA & Statistical Analysis\n",
      "   2. ğŸ› ï¸ Feature Engineering & Customer Segmentation\n",
      "   3. ğŸ¤– Machine Learning Models for Prediction\n",
      "   4. ğŸ“ˆ Interactive Dashboards & Business Insights\n",
      "\n",
      "âœ… NOTEBOOK 1 COMPLETE!\n",
      "ğŸ† Successfully demonstrated:\n",
      "   â€¢ Data generation and simulation skills\n",
      "   â€¢ Comprehensive data quality assessment\n",
      "   â€¢ Business metrics calculation\n",
      "   â€¢ Data preprocessing and optimization\n"
     ]
    }
   ],
   "source": [
    "# Export processed data\n",
    "print(\"ğŸ’¾ EXPORTING PROCESSED DATA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Export to CSV format for compatibility\n",
    "transactions_df.to_csv('../data/processed/transactions_clean.csv', index=False)\n",
    "customers_df.to_csv('../data/processed/customers.csv', index=False)\n",
    "\n",
    "print(\"âœ… Data exported successfully:\")\n",
    "print(\"   ğŸ“„ ../data/processed/transactions_clean.csv\")\n",
    "print(\"   ğŸ“„ ../data/processed/customers.csv\")\n",
    "\n",
    "# Save business metrics\n",
    "import json\n",
    "with open('../data/processed/business_metrics.json', 'w') as f:\n",
    "    json.dump(business_metrics, f, indent=2, default=str)\n",
    "\n",
    "print(\"   ğŸ“Š ../data/processed/business_metrics.json\")\n",
    "\n",
    "print(\"\\nğŸ¯ NEXT STEPS:\")\n",
    "print(\"   1. ğŸ“Š Continue to Notebook 2: Advanced EDA & Statistical Analysis\")\n",
    "print(\"   2. ğŸ› ï¸ Feature Engineering & Customer Segmentation\") \n",
    "print(\"   3. ğŸ¤– Machine Learning Models for Prediction\")\n",
    "print(\"   4. ğŸ“ˆ Interactive Dashboards & Business Insights\")\n",
    "\n",
    "print(\"\\nâœ… NOTEBOOK 1 COMPLETE!\")\n",
    "print(\"ğŸ† Successfully demonstrated:\")\n",
    "print(\"   â€¢ Data generation and simulation skills\")\n",
    "print(\"   â€¢ Comprehensive data quality assessment\") \n",
    "print(\"   â€¢ Business metrics calculation\")\n",
    "print(\"   â€¢ Data preprocessing and optimization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
